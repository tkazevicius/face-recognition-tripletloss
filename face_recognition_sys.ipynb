{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "N-9kzSG3oHfJ",
        "rSx0OMMmqaPT",
        "grhUZcNNwXec",
        "L9wefU6YsxC7",
        "kjk-eXPkuBnl"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ba37384d62e747ab879e511a0dcd7272": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4af8cbba83534b57bc45a674b32ea8ad",
              "IPY_MODEL_11d4e8a56c2a4804a6199e30e89442ea",
              "IPY_MODEL_ff0a69ef503b4eb68c38cf19a4bec093"
            ],
            "layout": "IPY_MODEL_ef1e218e94af4f09ab9d92fa28aef60f"
          }
        },
        "4af8cbba83534b57bc45a674b32ea8ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dffc577ae1554e118a7b681503a717f0",
            "placeholder": "​",
            "style": "IPY_MODEL_68822c6eb82a409bab2dacec90ac8280",
            "value": "100%"
          }
        },
        "11d4e8a56c2a4804a6199e30e89442ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0928252a869f441082b968fc368587bc",
            "max": 111898327,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e41fc058eba14932979d43ad81e2c740",
            "value": 111898327
          }
        },
        "ff0a69ef503b4eb68c38cf19a4bec093": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_facada7aefe246ab829de52e7c803a6a",
            "placeholder": "​",
            "style": "IPY_MODEL_06ac1585d01c4fa4a55023b785b92794",
            "value": " 107M/107M [00:02&lt;00:00, 48.4MB/s]"
          }
        },
        "ef1e218e94af4f09ab9d92fa28aef60f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dffc577ae1554e118a7b681503a717f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68822c6eb82a409bab2dacec90ac8280": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0928252a869f441082b968fc368587bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e41fc058eba14932979d43ad81e2c740": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "facada7aefe246ab829de52e7c803a6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06ac1585d01c4fa4a55023b785b92794": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Run General Setup**"
      ],
      "metadata": {
        "id": "N-9kzSG3oHfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Downloading \n",
        "!pip install flask\n",
        "!pip install pyngrok\n",
        "!pip install facenet-pytorch\n",
        "!pip install opencv-python\n",
        "!pip install seaborn\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "metadata": {
        "id": "rSWQswbSATH5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36546b78-59db-4684-c351-6fb02f923198"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (2.2.4)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask) (2.3.0)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.2)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask) (2.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-6.0.0.tar.gz (681 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m681.2/681.2 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-6.0.0-py3-none-any.whl size=19867 sha256=b08232ec69000b096fa274b8bd7b443706881a7517826b5d7bd56c3b5bfa4f55\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/42/78/0c3d438d7f5730451a25f7ac6cbf4391759d22a67576ed7c2c\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-6.0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting facenet-pytorch\n",
            "  Downloading facenet_pytorch-2.5.3-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (2.27.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (0.15.2+cu118)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch) (8.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->facenet-pytorch) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->facenet-pytorch) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->facenet-pytorch) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->facenet-pytorch) (3.4)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from torchvision->facenet-pytorch) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision->facenet-pytorch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision->facenet-pytorch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision->facenet-pytorch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision->facenet-pytorch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision->facenet-pytorch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision->facenet-pytorch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision->facenet-pytorch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision->facenet-pytorch) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchvision->facenet-pytorch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchvision->facenet-pytorch) (1.3.0)\n",
            "Installing collected packages: facenet-pytorch\n",
            "Successfully installed facenet-pytorch-2.5.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.7.0.72)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.12.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.22.4)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.5.3)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25->seaborn) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, render_template, request\n",
        "import sqlite3\n",
        "from google.colab import output\n",
        "from pyngrok import ngrok\n",
        "import cv2\n",
        "import io\n",
        "import csv\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as init\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL.Image\n",
        "import pickle\n",
        "from facenet_pytorch import InceptionResnetV1, fixed_image_standardization\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from flask import jsonify, flash, get_flashed_messages, request, send_file, redirect, session, url_for\n",
        "\n",
        "face_cascade = cv2.CascadeClassifier('/content/drive/MyDrive/triplet_loss/haarcascade_frontalface_default.xml')\n",
        "\n",
        "training_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0), ratio=(0.75, 1.3333333333333333), antialias=True),\n",
        "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "validation_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224), antialias=True),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "qpN_b0oXoOpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TripletFaceDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform):\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "        self.labels_to_images = self._get_labels_to_images()\n",
        "        \n",
        "    def _get_labels_to_images(self):\n",
        "        labels_to_images = {}\n",
        "        for root, dirs, files in os.walk(self.data_dir):\n",
        "            for file in files:\n",
        "                if file.endswith('.jpg') or file.endswith('JPEG') or file.endswith('jpeg'):\n",
        "                    label = os.path.basename(root)\n",
        "                    if label not in labels_to_images:\n",
        "                        labels_to_images[label] = []\n",
        "                    image_path = os.path.join(root, file)\n",
        "                    labels_to_images[label].append(image_path)\n",
        "        return labels_to_images\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.labels_to_images)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        labels = list(self.labels_to_images.keys())\n",
        "        anchor_label = random.choice(labels)\n",
        "        positive_label = anchor_label\n",
        "        negative_label = random.choice(labels)\n",
        "        while negative_label == anchor_label:\n",
        "            negative_label = random.choice(labels)\n",
        "                \n",
        "        anchor_positive_images = self.labels_to_images[anchor_label]\n",
        "        anchor_img_path = random.sample(anchor_positive_images, 1)[0]\n",
        "        positive_img_path = random.sample(list(set(anchor_positive_images) - set([anchor_img_path])), 1)[0]\n",
        "\n",
        "        negative_img_path = random.sample(self.labels_to_images[negative_label], 1)[0]\n",
        "        \n",
        "        anchor_img = self.transform(PIL.Image.open(anchor_img_path))\n",
        "        positive_img = self.transform(PIL.Image.open(positive_img_path))\n",
        "        negative_img = self.transform(PIL.Image.open(negative_img_path))\n",
        "        \n",
        "        return anchor_img, positive_img, negative_img"
      ],
      "metadata": {
        "id": "0MgNMekBoSfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InceptionResnetV1Model(nn.Module):\n",
        "    def __init__(self, embedding_size, pretrained=True, dropout_prob=0.6):\n",
        "        super(InceptionResnetV1Model, self).__init__()\n",
        "\n",
        "        self.model = InceptionResnetV1(pretrained='vggface2')\n",
        "\n",
        "        for param in self.model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        self.dropout = nn.Dropout(p=dropout_prob)\n",
        "        self.batchnorm = nn.BatchNorm1d(512)\n",
        "        self.fc = nn.Linear(512, embedding_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.batchnorm(x)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "RkKgttV6Km8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = InceptionResnetV1Model(embedding_size=128)\n",
        "model.classify = True\n",
        "\n",
        "for name, module in model.named_modules():\n",
        "    if isinstance(module, nn.Linear):\n",
        "        init.xavier_uniform_(module.weight)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "model_cpu = model.cpu()\n",
        "\n",
        "weight_decay = 0.00001\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=weight_decay)\n",
        "\n",
        "model_path = '/content/drive/MyDrive/triplet_loss/model_save.pt'"
      ],
      "metadata": {
        "id": "kPEXAvx0GnQa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "ba37384d62e747ab879e511a0dcd7272",
            "4af8cbba83534b57bc45a674b32ea8ad",
            "11d4e8a56c2a4804a6199e30e89442ea",
            "ff0a69ef503b4eb68c38cf19a4bec093",
            "ef1e218e94af4f09ab9d92fa28aef60f",
            "dffc577ae1554e118a7b681503a717f0",
            "68822c6eb82a409bab2dacec90ac8280",
            "0928252a869f441082b968fc368587bc",
            "e41fc058eba14932979d43ad81e2c740",
            "facada7aefe246ab829de52e7c803a6a",
            "06ac1585d01c4fa4a55023b785b92794"
          ]
        },
        "outputId": "dab70455-d83c-44da-88c0-7717272c3421"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/107M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ba37384d62e747ab879e511a0dcd7272"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def latest_model_state():\n",
        "  if torch.cuda.is_available():\n",
        "    checkpoint = torch.load(model_path)\n",
        "  else:\n",
        "    checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n",
        "\n",
        "  epoch = checkpoint['epoch']\n",
        "  model.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  loss = checkpoint['loss']\n",
        "\n",
        "with open('/content/drive/MyDrive/triplet_loss/embeddings_db.pkl', 'rb') as f:\n",
        "  known_embeddings = pickle.load(f)"
      ],
      "metadata": {
        "id": "Jl7w6IzGokaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Run Model**"
      ],
      "metadata": {
        "id": "rSx0OMMmqaPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_face(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "\n",
        "    if len(faces) == 0:\n",
        "        return None\n",
        "\n",
        "    (x, y, w, h) = faces[0]\n",
        "    cropped_image = image[y:y+h, x:x+w]\n",
        "\n",
        "    cropped_pil = PIL.Image.fromarray(cropped_image)\n",
        "\n",
        "    return cropped_pil"
      ],
      "metadata": {
        "id": "9N9vc64Eqfol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_match():\n",
        "    query_img = crop_face('/content/image.png')\n",
        "    if query_img == None:\n",
        "        return \"No match found\", 0\n",
        "    query_tensor = validation_transform(query_img).unsqueeze(0)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        query_embedding = model_cpu(query_tensor).squeeze().numpy()\n",
        "\n",
        "    distances = {}\n",
        "    for name, embeddings in known_embeddings.items():\n",
        "        distances[name] = torch.cdist(torch.tensor([query_embedding]), embeddings).squeeze().numpy()\n",
        "\n",
        "    min_distance = float('inf')\n",
        "    matching_name = None\n",
        "    for name, distance in distances.items():\n",
        "        avg_distance = distance.mean()\n",
        "        if avg_distance < min_distance:\n",
        "            min_distance = avg_distance\n",
        "            matching_name = name\n",
        "\n",
        "    # Normalize the distances between 0 and 1\n",
        "    min_distance_all = min(distances.values(), key=lambda x: x.mean()).mean()\n",
        "    max_distance_all = max(distances.values(), key=lambda x: x.mean()).mean()\n",
        "    normalized_distance = (min_distance - min_distance_all) / (max_distance_all - min_distance_all)\n",
        "\n",
        "    confidence_score = 1 - normalized_distance\n",
        "    confidence_threshold = 0.6\n",
        "\n",
        "    if confidence_score < confidence_threshold:\n",
        "        return \"No match found\", 0\n",
        "    else:\n",
        "        return matching_name, confidence_score"
      ],
      "metadata": {
        "id": "id7VGDDtrCcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_image():\n",
        "  img_data = request.get_data()\n",
        "  img_data_stream = io.BytesIO(img_data)\n",
        "  img = PIL.Image.open(img_data_stream)\n",
        "  img.save('image.png')"
      ],
      "metadata": {
        "id": "fCKT8xz_jZSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_id(name):\n",
        "  id = cursor.execute('select Darbuotojo_ID from timesheet where label=?;', (name,)).fetchone()\n",
        "  if id is None:\n",
        "    check = cursor.execute('select max(Darbuotojo_ID) + 1 FROM timesheet;').fetchone()[0]\n",
        "    if check is None:\n",
        "      return 1\n",
        "    else:\n",
        "      return cursor.execute('select max(Darbuotojo_ID) + 1 from timesheet;').fetchone()[0]\n",
        "  else:\n",
        "    return id[0]"
      ],
      "metadata": {
        "id": "q69EtvRQOPSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def insert_values(match_name, workers):\n",
        "  if match_name not in workers:\n",
        "    id = check_id(match_name)\n",
        "    cursor.execute(f\"insert into timesheet(Iraso_NR, Darbuotojo_ID ,label, Atvykimas, Isvykimas) values (NULL, {id}, '{match_name}', datetime('now', '+3 hour'), NULL);\")\n",
        "    message = \". Sveiki atvykę.\"\n",
        "  elif match_name in workers:\n",
        "    cursor.execute(f\"update timesheet set Isvykimas = datetime('now', '+3 hour') where label = ? and Iraso_NR = (select max(Iraso_NR) from timesheet where label=?);\", (match_name, match_name))\n",
        "    message = \". Viso gero.\"\n",
        "  connection.commit()\n",
        "  return message"
      ],
      "metadata": {
        "id": "YCcd6jkWiJB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_timesheet(name):\n",
        "  file_path = os.path.join('/content/drive/MyDrive/triplet_loss/downloadable', f'{name}_timesheet.csv')\n",
        "  with open(file_path, 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    if name == 'bendras':\n",
        "      cursor.execute(\"select * from timesheet\")\n",
        "    else:\n",
        "      cursor.execute(\"select * from timesheet where label=?\", (name,))\n",
        "    columns = [description[0] for description in cursor.description]\n",
        "    writer.writerow(columns)\n",
        "    rows = cursor.fetchall()\n",
        "    writer.writerows(rows)\n",
        "  return file_path"
      ],
      "metadata": {
        "id": "0A5C5ypn36rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_labels():\n",
        "  directory = '/content/drive/MyDrive/triplet_loss/faces'\n",
        "  if os.path.isdir(directory):\n",
        "    labels = [label for label in os.listdir(directory)]\n",
        "  return labels"
      ],
      "metadata": {
        "id": "jVPOImkJgRW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(model_path):\n",
        "  latest_model_state()\n",
        "\n",
        "app = Flask(__name__, template_folder='/content/drive/MyDrive/triplet_loss/templates')\n",
        "ngrok.set_auth_token(\"2Nk96yKFpLVyMgYnj073X7veRq2_LCALuFqnRHXMiwowDMT3\")\n",
        "app.secret_key = 'secret_key'\n",
        "port_number=4500;\n",
        "public_url = ngrok.connect(port_number).public_url\n",
        "\n",
        "connection = sqlite3.connect('/content/drive/MyDrive/triplet_loss/database/timesheet.db', check_same_thread=False)\n",
        "cursor = connection.cursor()\n",
        "worker_set = set()\n",
        "depart_set = set()\n",
        "\n",
        "@app.route('/process_data', methods=['POST'])\n",
        "def process_data():\n",
        "  process_image()\n",
        "  match_name, confidence = find_match()\n",
        "  if match_name == \"No match found\":\n",
        "    flash(\"Neužfiksuotas veidas arba nerastas atitikmuo. Prašome bandyti iš naujo\")\n",
        "  if match_name in depart_set:\n",
        "    flash(f\"Jau užfiksuotas šio asmens ({match_name}) atvykimo ir išvykimo laikas. Viso gero\")\n",
        "  elif match_name != \"No match found\":\n",
        "    message = insert_values(match_name, worker_set)\n",
        "    if message == \". Viso gero.\":\n",
        "      depart_set.add(match_name)\n",
        "    worker_id = cursor.execute(\"select Darbuotojo_ID from timesheet where label = ?\", (match_name,)).fetchone()[0]\n",
        "    flash(f\"Atitikmuo rastas. Įsitikinimas: {confidence:.2f}. Darbuotojo ID: {worker_id}, etiketė: {match_name}\" + message)\n",
        "    worker_set.add(match_name)\n",
        "  return render_template('index.html')\n",
        "\n",
        "@app.route('/flash_messages')\n",
        "def get_flash_messages():\n",
        "  messages = get_flashed_messages()\n",
        "  return jsonify(messages)\n",
        "\n",
        "@app.route('/login', methods=['GET', 'POST'])\n",
        "def admin_login():\n",
        "  if request.method == 'POST' and 'username' in request.form and 'password' in request.form:\n",
        "    username = request.form['username']\n",
        "    password = request.form['password']\n",
        "    if username == 'admin' and password == 'admin':\n",
        "      session[\"logged_in\"] = True\n",
        "      return redirect('admin')    \n",
        "  return render_template(\"login.html\")\n",
        "\n",
        "@app.before_request\n",
        "def check_logged_in():\n",
        "    if 'logged_in' not in session and request.endpoint == 'admin_page':\n",
        "        return redirect('login')\n",
        "\n",
        "@app.route('/admin')\n",
        "def admin_page():\n",
        "  cursor.execute(\"select * from timesheet order by rowid desc limit 15\")\n",
        "  rows = cursor.fetchall()\n",
        "  labels = get_labels()\n",
        "  return render_template('admin.html', rows = rows, labels = labels)\n",
        "\n",
        "@app.route('/download', methods=['GET'])\n",
        "def download_file():\n",
        "  name = request.args.get('name')\n",
        "  file_path = create_timesheet(name)\n",
        "  return send_file(file_path, as_attachment=True)\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "  return render_template('index.html')\n",
        "\n",
        "print(f\"To access the system, please use this link: {public_url}\")\n",
        "\n",
        "app.run(port=port_number)\n",
        "\n",
        "connection.close()"
      ],
      "metadata": {
        "id": "_jsvZfktrHx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train Model**"
      ],
      "metadata": {
        "id": "grhUZcNNwXec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "data_dir = '/content/drive/MyDrive/triplet_loss/faces'\n",
        "training_dataset = TripletFaceDataset(data_dir=data_dir, transform=training_transform)\n",
        "training_dataloader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "validation_dir = '/content/drive/MyDrive/triplet_loss/validation_set'\n",
        "validation_dataset = TripletFaceDataset(data_dir=validation_dir, transform=validation_transform)\n",
        "validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "criterion = nn.TripletMarginLoss(margin=1.0, p=2.0, reduction='mean')"
      ],
      "metadata": {
        "id": "ZE5LYi3rYFIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(model_path):\n",
        "  latest_model_state()\n",
        "\n",
        "num_epochs = 50\n",
        "patience = 10\n",
        "counter = 0\n",
        "average_loss = 0\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    model.train()\n",
        "    for anchor, positive, negative in training_dataloader:\n",
        "\n",
        "        anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        embedding_anchor, embedding_positive, embedding_negative = model(anchor), model(positive), model(negative)\n",
        "        loss = criterion(embedding_anchor, embedding_positive, embedding_negative)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    epoch_train_loss = running_loss / len(training_dataloader)\n",
        "\n",
        "    # validation loop\n",
        "    running_loss = 0.0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for anchor, positive, negative in validation_dataloader:\n",
        "\n",
        "            anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
        "\n",
        "            embedding_anchor, embedding_positive, embedding_negative = model(anchor), model(positive), model(negative)\n",
        "            loss = criterion(embedding_anchor, embedding_positive, embedding_negative)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        epoch_val_loss = running_loss / len(validation_dataloader)\n",
        "\n",
        "        if epoch_val_loss < best_val_loss and epoch_val_loss != 0:\n",
        "            best_val_loss = epoch_val_loss\n",
        "            counter = 0\n",
        "            torch.save({\n",
        "                        'epoch': epoch,\n",
        "                        'model_state_dict': model.state_dict(),\n",
        "                        'optimizer_state_dict': optimizer.state_dict(),\n",
        "                        'loss': loss\n",
        "                        }, model_path)\n",
        "        else:\n",
        "            counter += 1\n",
        "\n",
        "    average_loss += epoch_train_loss\n",
        "    print('Epoch [%d/%d], Training Loss: %.4f, Validation Loss: %.4f' % (epoch+1, num_epochs, epoch_train_loss, epoch_val_loss))\n",
        "\n",
        "    if counter >= patience:\n",
        "        print(\"Early stopping at epoch\", epoch + 1)\n",
        "        break\n",
        "\n",
        "average_loss /= num_epochs\n",
        "print('Average training loss: %.4f' % average_loss)"
      ],
      "metadata": {
        "id": "IFSWL40pm5Gv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test Model**"
      ],
      "metadata": {
        "id": "L9wefU6YsxC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TestDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform=validation_transform):\n",
        "        self.data_dir = data_dir\n",
        "        self.file_names = os.listdir(data_dir)\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        self.labels = [file_name.split(\"-\")[0] for file_name in self.file_names]\n",
        "        self.label_encoder.fit(self.labels)\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.file_names)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        file_name = self.file_names[index]\n",
        "        img_path = os.path.join(self.data_dir, file_name)\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = PIL.Image.fromarray(img)\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        label = self.labels[index]\n",
        "        label = self.label_encoder.transform([label])[0]\n",
        "        return img, label"
      ],
      "metadata": {
        "id": "ahHm5bEFctX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_closest_class(embedding, known_embeddings):\n",
        "    min_distance = float('inf')\n",
        "    closest_class = None\n",
        "    for class_name, class_embeddings in known_embeddings.items():\n",
        "        distances = [torch.dist(embedding, class_emb) for class_emb in class_embeddings]\n",
        "        avg_distance = np.mean(distances)\n",
        "        if avg_distance < min_distance:\n",
        "            min_distance = avg_distance\n",
        "            closest_class = class_name\n",
        "    return closest_class"
      ],
      "metadata": {
        "id": "jrIvykmJH0by"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "batch_size = 64\n",
        "test_dir = '/content/drive/MyDrive/triplet_loss/testing_set'\n",
        "test_dataset = TestDataset(data_dir=test_dir)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "model.eval()\n",
        "\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_dataloader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        embeddings = model(images)\n",
        "        \n",
        "        for i, embedding in enumerate(embeddings):\n",
        "            predicted = get_closest_class(embedding, known_embeddings)\n",
        "            total += 1\n",
        "            true_label = test_dataset.label_encoder.inverse_transform([labels[i].item()])[0]\n",
        "            true_labels.append(true_label)\n",
        "            predicted_labels.append(predicted)\n",
        "            if predicted == true_label:\n",
        "                correct += 1\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print('Accuracy on test images: {:.2f}%'.format(accuracy))\n",
        "\n",
        "conf_mat = confusion_matrix(true_labels, predicted_labels)\n",
        "conf_mat_normalized = conf_mat.astype('float') / conf_mat.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "sns.heatmap(conf_mat_normalized, annot=True, cmap='Blues', xticklabels=test_dataset.label_encoder.classes_, yticklabels=test_dataset.label_encoder.classes_)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "i43OgqADHBDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Crop Faces, Create Embeddings & SQLite Database**"
      ],
      "metadata": {
        "id": "kjk-eXPkuBnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "directory= ''\n",
        "image_dir = f'/content/drive/MyDrive/triplet_loss/temporary/{directory}'\n",
        "\n",
        "output_dir = f'/content/drive/MyDrive/triplet_loss/temporary/{directory}_cropped'\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "  os.makedirs(output_dir)\n",
        "\n",
        "for filename in os.listdir(image_dir):\n",
        "\n",
        "  image_path = os.path.join(image_dir, filename)\n",
        "  image = cv2.imread(image_path)\n",
        "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "  \n",
        "  for i, (x, y, w, h) in enumerate(faces):\n",
        "    face = image[y:y+h, x:x+w]\n",
        "    output_path = os.path.join(output_dir, f'{filename.split(\".\")[0]}_face{i}.jpg')\n",
        "    cv2.imwrite(output_path, face)"
      ],
      "metadata": {
        "id": "kfAjDaYtuG2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "data_dir='/content/drive/MyDrive/triplet_loss/faces'\n",
        "known_embeddings = {}\n",
        "\n",
        "for name in os.listdir(data_dir):\n",
        "    name_path = os.path.join(data_dir, name)\n",
        "    if os.path.isdir(name_path):\n",
        "        embeddings = []\n",
        "        for img_name in os.listdir(name_path):\n",
        "            img_path = os.path.join(name_path, img_name)\n",
        "            img = PIL.Image.open(img_path)\n",
        "            img_tensor = validation_transform(img).unsqueeze(0)\n",
        "            with torch.no_grad():\n",
        "                embedding = model(img_tensor).squeeze().numpy()\n",
        "                embeddings.append(embedding)\n",
        "        known_embeddings[name] = torch.tensor(embeddings)\n",
        "\n",
        "with open('/content/drive/MyDrive/triplet_loss/embeddings_db.pkl', 'wb') as f:\n",
        "    pickle.dump(known_embeddings, f)"
      ],
      "metadata": {
        "id": "QZyRtV7exewE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext sql"
      ],
      "metadata": {
        "id": "w5mNZI1cdZ2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%sql sqlite:////content/drive/MyDrive/triplet_loss/database/timesheet.db"
      ],
      "metadata": {
        "id": "lbCFkhztdbOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "\n",
        "drop table timesheet\n",
        "\n",
        "create table timesheet(Iraso_NR integer primary key, Darbuotojo_ID varchar, label varchar, Atvykimas datetime, Isvykimas datetime);"
      ],
      "metadata": {
        "id": "f8xzgSNsMq0w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}